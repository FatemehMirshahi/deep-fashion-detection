---

- step:
    name: Train model
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - nsteps={parameters}
      - pip3 install tf-nightly-gpu
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - cd object_detection/
      - mkdir -p training
      - cp /valohai/repository/faster_rcnn_inception_resnet_v2_atrous_coco.config training/
      - sed -i -e "114s/num_steps&#58; 200000/num_steps&#58; $nsteps/" training/faster_rcnn_inception_resnet_v2_atrous_coco.config
      - mkdir training/data
      - cp /valohai/repository/deepfashion_label_map.pbtxt training/data/
      - cp /valohai/inputs/train_records/train.record training/data/
      - cp /valohai/inputs/val_records/val.record training/data/
      - mkdir training/models
      - tar -xzvf /valohai/inputs/pretrained_net/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz -C training/models/ --strip-components=1
      - mkdir training/models/train
      - cp train.py training/
      - cp export_inference_graph.py training/
      - cd training/
      - python3 train.py --logtostderr --train_dir=./models/train --pipeline_config_path=faster_rcnn_inception_resnet_v2_atrous_coco.config
      - python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path ./faster_rcnn_inception_resnet_v2_atrous_coco.config --trained_checkpoint_prefix ./models/train/model.ckpt-$nsteps --output_directory ./fine_tuned_model
      - zip -r fine_tuned_model.zip fine_tuned_model
      - mv fine_tuned_model.zip /valohai/outputs/
    inputs:
      - name: train_records
      - name: val_records
      - name: pretrained_net
        default: http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28.tar.gz
    parameters:
      - name: number_steps
        type: integer
        pass-as: {v}
        description: Number of steps to run the trainer
        default: 200000

- step:
    name: Dataset preparation
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - cp /valohai/repository/deep_fashion_to_tfrecord.py object_detection/
      - cd object_detection
      - mkdir -p category_and_attribute_prediction_benchmark
      - echo "Unzipping deep fashion dataset..."
      - unzip -q /valohai/inputs/category_and_attribute_prediction_benchmark/AACt2dLasqSDsCf-kcQwoWyfa -d category_and_attribute_prediction_benchmark/ -x /
      - cd category_and_attribute_prediction_benchmark/Img/
      - unzip -q img.zip
      - cd ../../
      - echo "Formatting training images to tfrecord..."
      - python3 deep_fashion_to_tfrecord.py --output_path train.record --categories broad --evaluation_status train
      - echo "Formatting validation images to tfrecord..."
      - python3 deep_fashion_to_tfrecord.py --output_path val.record --categories broad --evaluation_status val
      - echo "Formatting test images to tfrecord..."
      - python3 deep_fashion_to_tfrecord.py --output_path test.record --categories broad --evaluation_status test
      - mv *.record /valohai/outputs/
    inputs:
      - name: category_and_attribute_prediction_benchmark
        default: https://www.dropbox.com/sh/ryl8efwispnjw21/AACt2dLasqSDsCf-kcQwoWyfa?dl=1

- step:
    name: Worker environment check
    image: dcarnino/docker-tensorflow-object-detection
    command:
      - pwd
      - ls -la
      - ls /tensorflow/
      - nvidia-smi
      - python --version
      - nvcc --version | grep release
      - cat /usr/include/x86_64-linux-gnu/cudnn_v*.h | grep CUDNN_MAJOR -A 2
      - cd /tensorflow/models/research/
      - export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim
      - python3 object_detection/builders/model_builder_test.py
